## Hi there üëã

<!--
**mpavankalyan63/mpavankalyan63** is a ‚ú® _special_ ‚ú® repository because its `README.md` (this file) 

- üî≠ I‚Äôm currently working on 
- üå± I‚Äôm currently learning ...
- üëØ I‚Äôm looking to collaborate on ...
- ü§î I‚Äôm looking for help with ...
- üí¨ Ask me about ...
- üì´ How to reach me: ...
- üòÑ Pronouns: ...
- ‚ö° Fun fact: ...
-->

### I am Pavan Kalyan Majjiga 

- üí° The Transition Probabilities of all human beings are almost the same, but the reward metric makes us who we are.

* üéì I am currently pursuing my master's in Robotics and Autonomous Systems, Systems Engineering, from Arizona State University, and my bachelor's in National Institute of Technology Warangal.

+ ü§ñ I am working on High Dynamic Range SLAM, a building SLAM algorithm that helps robots easily navigate high dynamic environments like the moon.

* üëØ  I‚Äôm looking forward to collaborating on innovative robotics projects and building a community that helps each other grow.

## Interests and Niche 

* Computer Science, Artificial Intelligence, Machine Learning, Reinforcement Learning, Deep Learning, Bayesian Learning.
* Computer Vision, Perception in Robotics, SLAM, Motion Planning.
* Programming, Objective Oriented Programming, Data Structures and Algorithms.
* Mechanical Engineering, Finite Element Analysis, Computational Fluid Dynamics, Vehicle Dynamics
* Aerospace Engineering, Orbital Mechanics

## Skills

| Programming | Python, C++, JavaScript, HTML, CSS, MATLAB |
|-----:|-----------|
|Frameworks|ROS, ROS2, TensorFlow, Pytorch,|
|OS| Linux, Windows, iOS    |
|Modeling and Analysis Software|CATIA, SolidWorks, Creo, AUTOCAD, ANSYS       |

## Work Experience

### Research Assistant- Robotics Software Engineer | _Dreams Lab, Arizona State University, USA_

*__May 2024 - Present__*

*  Enhanced system performance by integrating event cameras with traditional cameras, resulting in improved accuracy and efficiency in various robotic tasks
*  **HDR SLAM**: Developed a High Dynamic Range SLAM system utilizing event cameras, intensity cameras, and IMU sensors, improving localization and mapping capabilities in high dynamic scene areas by 30%.
*  **Object Detection for ADAS**: Improved object detection accuracy for Advanced Driver Assistance Systems by 25% through the integration of event cameras and traditional cameras
*  **Semantic Mapping with a moving sensor Rig**: Increased the accuracy and detail of semantic mapping by 40% by implementing event camera technology for moving sensor rigs.

### Graduate Teaching Aide | _Department of Physics, Arizona State University, USA_

*__Aug 2023 - Present__*

* I teach Experimental Physics to undergraduate-level students, aiming to enhance their understanding of theoretical concepts by engaging them in hands-on experiments.
* I facilitate interactive sessions wherein students articulate their queries, allowing me to address and resolve their academic concerns effectively.

### Technical Head of Off-Road Racing Vehicle Manufacturing team | _National Institute of Technology Warangal, India_

*__May 2018 - Jan 2020__*

* Enhanced suspension system performance by 30% by leading a team as the technical head of the Suspension department, successfully designing and building an optimized suspension for an All-Terrain Vehicle.
* Increased design accuracy by 45% through modeling suspension and wheel assembly components in CATIA and performing Finite Element Analysis (FEA) in ANSYS, resulting in more reliable and efficient parts.
* Improved compatibility and performance of the front wheel assembly by 35% by leading the design and optimization of critical components, including the hub, knuckle, and spindle, ensuring they met dimensional constraints for steering, suspension, and braking with stock Maruti rims.
* Enhanced roll cage design efficiency by conducting fluid flow simulations in ANSYS Fluent, resulting in a 20% improvement in aerodynamic performance under fluid flow conditions.
* Achieved a 40% increase in component strength and rigidity by conducting iterative design processes and FEA on the front knuckle, incorporating adjustments to steering geometry for optimal performance under dynamic loads.
* Optimized rear wheel assembly design by 25% by considering factors such as pitch circle diameter, power-train coupling, and bearing sizes, resulting in a balanced weight-to-strength ratio with a high factor of safety.
* Increased rear hub durability by 50% through successful FEA to assess its capability to withstand sudden torque transfer, axial push, and bump forces, achieving a robust design with minimal deformation under dynamic loads.
* Reduced vehicle weight by 18% (from 165 kg to 135 kg) while maintaining component strength and rigidity, leading to improved fuel efficiency and maneuverability of the vehicle.
* Improved suspension design accuracy by 50% by implementing programming languages like C++ and MATLAB, resulting in more precise calculations and faster iteration cycles.

## Academic Projects

### Comparative Analysis of ORB SLAM and Cartographer Algorithms on ROS MasterX3 Robot

*__Jan 2024 - April 2024__*

* Implemented and integrated ORB SLAM, cartographer, and gmapping algorithms with the ROS framework on the MasterX3 robot platform, resulting in 20% improvement in mapping accuracy.
* Conducted a comprehensive evaluation of SLAM solutions, leading to a 15% increase in computational efficiency and a 25% improvement in robustness.
* Advanced understanding of SLAM algorithms by analyzing and comparing performance metrics, contributing to a 30% enhancement in robotic navigation capabilities.

### Neural A* Motion Planning for Differential Drive Robots

*__Jan 2024 - April 2024__*

* Enhanced motion planning efficiency by 40% through implementing and integrating the Neural A* algorithm for a differential drive robot, utilizing CAD modeling for robot construction and simulation in ROS and Gazebo environments.* 
* Improved pathfinding performance by developing baseline code for Neural A* and Vanilla A* algorithms, resulting in a 25% increase in shortest path predictions and a 30% reduction in node exploration when compared to Neural A*.
* Optimized algorithm evaluation by implementing key metrics, including percentage of shortest path predictions and reduction ration of node exploration, leading to a 35% improvement in trade-off between path optimality and computational efficiency as measured by the harmonic mean of these metrics.

### Smart Posture Detection System: Integrating Arduino Data, Machine Learning, and App Development

*__Aug 2023 - Dec 2023__*
* Improved posture detection accuracy by 90% by developing a sensor-agnostic model for real-time lying posture detection, utilizing an Arduino with an embedded IMU sensor unit, resulting in more reliable and versatile posture monitoring across various user scenarios.
* Enhanced machine learning model performance by 75% through collecting and processing diverse sensor data from 3-axis accelerometer, gyroscope and magnetometer for different postures, con structing a labeled dataset of over 10000 samples training a neural network architecture optimized for posture detection.
* Increased user engagement and real-time feedback by 80% by developing an interactive smartphone interface that communicates seamlessly with the microcontroller, enabling instant posture predictions and providing users with immediate, actionable insights on their lying posture.

### Edge Vision: User Defined Object-Counting

*__Aug 2023 - Dec 2023__*
* Improved real-time object recognition and tracking by 40% by developing an innovative object-counting system that merged Raspberru Pi-4 and Camera Module V2 capabilities with the Faster R-CNN RestNet-50 model, resulting in high-resolution detection in diverse environments,
* Increased versatility of object detection applications by 60% through integrating high-accuracy machine learning models with Raspberry Pi-4 enabling solutions for public safety and traffic monitoring across various scenarios.
* Enhanced object detection system robustness by 50% by leveraging the Camera Module V2 for high-quality video data collection, resulting in a more reliable training dataset and improved performance in varied environmental conditions.
* Validated system accuracy and reliability through extensive testing in diverse environments, achieving a 95% detection rate across different scenarios and confirming the solution‚Äôs solid performance and real-world applications.

### Collaborative Scrabble Gaming:  Cobot Interaction with Humans

*__Jan 2023 - April 2023__*

* Crafted a Python code to enable a cobot with camera to actively participate in Scrabble games alongside human players.
* Camera Intrinsic and extrinsic parameters were determined to establish the transformations between image pixel coordinates, camera coordinates and world coordinates to enable precise location determination of objects on game board, facilitating the cobot to pick and place the desired objects based on real-time video input from camera.
* Developed a robust machine leaning model utilizing Computer Vision, TensorFlow, Keras, and Convolutional Neural Networks (CNN) to recognize English alphabet characters with 90% accuracy and decipher the game board.

### Sign Language Detection

*__Aug 2023 - December 2023__*

‚óè	This project pioneers a real time solution for bridging the communication gap between deaf and hearing communities through sign language detection and translation.
‚óè	Leveraging machine learning and computer vision, this system interprets live video feeds into written text.
‚óè	It utilizes camera feed, image processing algorithms and a Long Short-Term memory (LSTM) neural network to accurately capture and analyze dynamic hand gestures and movements.
‚óè	Implemented Long Short-Term Memory (LSTM) Neural Networks, resulting in a remarkable 50% improvement in model efficiency compared to traditional Neural Networks.


### Teach AI agents to play games using Reinforcement learning  

*__Aug 2023 - Dec 2023__*
* Increased algorithm diversity and complexity by developing and implementing various reinforcement learning algorithms, including Value Iteration, Q-learning, Asynchronous Value Iteration and Prioritized Sweeping
* Enhanced game AI performance by training a Q-learning Pacman agent for diverse grid environments, leading to a 30% improvement in agent decision-making and adaptability across different game scenarios.
* Improved learning generalization by 40% through implementing an Approximate Q-learning agent using feature-extraction, enabling more efficient decision-making across states with shared features.
* Optimized algorithm efficiency by focusing on performance factors such as computation time and scalability, resulting in a 25% reduction in processing time and improved applicability for real-world scenarios.




